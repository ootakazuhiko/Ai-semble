# データセット可視化機能 テスト仕様書

## 1. テスト概要

### 1.1 テスト目的

データセット可視化機能の品質を確保するため、以下の観点でテストを実施する：

- 機能の正確性
- パフォーマンス
- セキュリティ
- エラー処理
- ユーザビリティ

### 1.2 テスト範囲

- APIエンドポイント
- 可視化サービス
- データ処理
- キャッシュ機能
- エラーハンドリング

### 1.3 テスト環境

- 開発環境
  - OS: Windows 10/11, Linux
  - Python: 3.9以上
  - データベース: PostgreSQL 13以上
  - メモリ: 最小8GB
  - CPU: 最小4コア

- テストデータ
  - サンプルデータセット（小/中/大規模）
  - エッジケースデータ
  - 不正データ

## 2. テストケース

### 2.1 単体テスト

#### 2.1.1 可視化サービス（`VisualizationService`）

##### 統計情報ダッシュボード生成

| テストID | テスト内容 | 入力 | 期待結果 | 備考 |
|----------|------------|------|----------|------|
| VS-001 | 正常系：数値データのみ | 数値カラムのみのデータセット | ヒストグラム、基本統計量を表示 | 欠損値なし |
| VS-002 | 正常系：カテゴリカルデータのみ | カテゴリカルカラムのみのデータセット | 棒グラフ、頻度表を表示 | 欠損値なし |
| VS-003 | 正常系：混合データ | 数値・カテゴリカル混合データセット | 両方の可視化を表示 | 欠損値なし |
| VS-004 | 異常系：空データセット | 空のデータセット | 適切なエラーメッセージ | エラーコード: 404 |
| VS-005 | 異常系：不正なデータ型 | 不正なデータ型を含むデータセット | 適切なエラーメッセージ | エラーコード: 400 |

##### バージョン比較ダッシュボード生成

| テストID | テスト内容 | 入力 | 期待結果 | 備考 |
|----------|------------|------|----------|------|
| VC-001 | 正常系：同一スキーマ | 同じスキーマの2バージョン | 差分を強調表示 | データの変更のみ |
| VC-002 | 正常系：スキーマ変更 | スキーマが異なる2バージョン | スキーマ差分を表示 | カラムの追加/削除 |
| VC-003 | 異常系：存在しないバージョン | 不正なバージョン指定 | 適切なエラーメッセージ | エラーコード: 404 |
| VC-004 | 異常系：同一バージョン | 同じバージョンを指定 | 適切なエラーメッセージ | エラーコード: 400 |

##### 品質指標ダッシュボード生成

| テストID | テスト内容 | 入力 | 期待結果 | 備考 |
|----------|------------|------|----------|------|
| QM-001 | 正常系：時系列データ | 複数バージョンの品質指標 | 時系列グラフを表示 | トレンド表示 |
| QM-002 | 正常系：単一バージョン | 単一バージョンの品質指標 | 現在の指標を表示 | スナップショット |
| QM-003 | 異常系：指標なし | 品質指標が未計算 | 適切なエラーメッセージ | エラーコード: 404 |

#### 2.1.2 APIエンドポイント

##### 統計情報ダッシュボード取得

| テストID | テスト内容 | リクエスト | 期待結果 | 備考 |
|----------|------------|------------|----------|------|
| API-001 | 正常系：JSON形式 | GET /statistics?format=json | JSONレスポンス | ステータス: 200 |
| API-002 | 正常系：HTML形式 | GET /statistics?format=html | HTMLレスポンス | ステータス: 200 |
| API-003 | 異常系：未認証 | 認証ヘッダーなし | 認証エラー | ステータス: 401 |
| API-004 | 異常系：権限なし | 読み取り権限なし | 認可エラー | ステータス: 403 |
| API-005 | 異常系：不正なフォーマット | 不正なformat指定 | バリデーションエラー | ステータス: 400 |

##### バージョン比較ダッシュボード取得

| テストID | テスト内容 | リクエスト | 期待結果 | 備考 |
|----------|------------|------------|----------|------|
| API-006 | 正常系：2バージョン指定 | GET /version-comparison?v1=1&v2=2 | 比較ダッシュボード | ステータス: 200 |
| API-007 | 異常系：バージョン未指定 | バージョン指定なし | バリデーションエラー | ステータス: 400 |
| API-008 | 異常系：不正なバージョン | 不正なバージョン指定 | エラーメッセージ | ステータス: 404 |

##### 品質指標ダッシュボード取得

| テストID | テスト内容 | リクエスト | 期待結果 | 備考 |
|----------|------------|------------|----------|------|
| API-009 | 正常系：全期間 | GET /quality-metrics | 全期間の指標 | ステータス: 200 |
| API-010 | 正常系：期間指定 | GET /quality-metrics?start=2024-01-01 | 指定期間の指標 | ステータス: 200 |
| API-011 | 異常系：不正な期間 | 不正な日付形式 | バリデーションエラー | ステータス: 400 |

### 2.2 統合テスト

#### 2.2.1 エンドツーエンドテスト

| テストID | テスト内容 | シナリオ | 期待結果 | 備考 |
|----------|------------|----------|----------|------|
| E2E-001 | ダッシュボード生成フロー | 1. データセット選択<br>2. 統計情報表示<br>3. バージョン比較<br>4. 品質指標表示 | 全機能が正常動作 | 正常系 |
| E2E-002 | エラー処理フロー | 1. 不正なデータセット選択<br>2. エラーメッセージ確認<br>3. リカバリー操作 | 適切なエラー処理 | 異常系 |
| E2E-003 | 認証フロー | 1. 未認証アクセス<br>2. ログイン<br>3. 機能利用 | 認証の正常動作 | セキュリティ |

#### 2.2.2 パフォーマンステスト

| テストID | テスト内容 | 条件 | 期待結果 | 備考 |
|----------|------------|------|----------|------|
| PERF-001 | レスポンスタイム | 小規模データセット | 3秒以内 | 通常負荷 |
| PERF-002 | レスポンスタイム | 大規模データセット | 10秒以内 | 高負荷 |
| PERF-003 | 同時実行 | 10ユーザー同時アクセス | エラーなし | 負荷テスト |
| PERF-004 | メモリ使用量 | 大規模データセット処理 | 8GB以内 | リソース監視 |
| PERF-005 | キャッシュ効果 | 同一データセット連続アクセス | 2回目以降1秒以内 | キャッシュテスト |

### 2.3 セキュリティテスト

| テストID | テスト内容 | テスト方法 | 期待結果 | 備考 |
|----------|------------|------------|----------|------|
| SEC-001 | 認証テスト | トークンなしアクセス | 認証エラー | ステータス: 401 |
| SEC-002 | 認可テスト | 権限なしアクセス | 認可エラー | ステータス: 403 |
| SEC-003 | トークン検証 | 不正なトークン | 認証エラー | ステータス: 401 |
| SEC-004 | データアクセス | 他ユーザーのデータセット | アクセス拒否 | ステータス: 403 |
| SEC-005 | 入力検証 | SQLインジェクション試行 | バリデーションエラー | ステータス: 400 |

## 3. テスト実施手順

### 3.1 準備

1. テスト環境のセットアップ
   ```bash
   # 仮想環境の作成
   python -m venv venv
   source venv/bin/activate  # Linux
   .\venv\Scripts\activate   # Windows
   
   # 依存パッケージのインストール
   pip install -r requirements.txt
   pip install -r requirements-dev.txt
   
   # テストデータベースの準備
   python scripts/setup_test_db.py
   ```

2. テストデータの準備
   ```python
   # テストデータの生成
   python scripts/generate_test_data.py \
       --size small \
       --output test_data/small_dataset.csv
   
   python scripts/generate_test_data.py \
       --size large \
       --output test_data/large_dataset.csv
   ```

### 3.2 テスト実行

1. 単体テストの実行
   ```bash
   # 全テストの実行
   pytest tests/
   
   # 特定のテストの実行
   pytest tests/test_visualization.py -v
   
   # カバレッジレポートの生成
   pytest --cov=src tests/ --cov-report=html
   ```

2. 統合テストの実行
   ```bash
   # 統合テストの実行
   pytest tests/integration/ -v
   
   # パフォーマンステストの実行
   pytest tests/performance/ -v
   ```

3. セキュリティテストの実行
   ```bash
   # セキュリティテストの実行
   pytest tests/security/ -v
   
   # 脆弱性スキャン
   bandit -r src/
   ```

### 3.3 テスト結果の確認

1. テストレポートの確認
   - `htmlcov/index.html`：カバレッジレポート
   - `test-results/`：テスト実行結果
   - `security-report.html`：セキュリティテスト結果

2. パフォーマンスメトリクスの確認
   - レスポンスタイム
   - メモリ使用量
   - CPU使用率
   - キャッシュヒット率

## 4. テスト結果の評価基準

### 4.1 合格基準

1. 機能テスト
   - 全テストケースの95%以上が成功
   - クリティカルな機能は100%成功
   - エラー処理が適切に動作

2. パフォーマンステスト
   - レスポンスタイムが要件を満たす
   - メモリ使用量が制限内
   - 同時実行時の安定性

3. セキュリティテスト
   - 認証・認可が適切に機能
   - 脆弱性が検出されない
   - データ保護が確実

### 4.2 品質メトリクス

1. コードカバレッジ
   - ステートメント: 90%以上
   - ブランチ: 85%以上
   - 関数: 95%以上

2. パフォーマンス指標
   - 平均レスポンスタイム: 3秒以内
   - 95パーセンタイル: 5秒以内
   - エラー率: 1%未満

3. セキュリティ指標
   - 脆弱性: 0件
   - セキュリティ警告: 0件
   - コンプライアンス: 100%適合

## 5. テスト環境の管理

### 5.1 環境変数

```bash
# テスト環境の設定
export TEST_ENV=development
export TEST_DB_URL=postgresql://test:test@localhost:5432/test_db
export TEST_CACHE_URL=redis://localhost:6379/0
export TEST_LOG_LEVEL=DEBUG
```

### 5.2 テストデータ管理

1. テストデータのバージョン管理
   - テストデータはGit LFSで管理
   - 定期的な更新と検証
   - バックアップの保持

2. テストデータの種類
   - 小規模データセット（1,000行）
   - 中規模データセット（10,000行）
   - 大規模データセット（100,000行）
   - エッジケースデータ
   - 不正データ

### 5.3 テスト環境のクリーンアップ

```bash
# テスト環境のクリーンアップ
python scripts/cleanup_test_env.py

# テストデータベースのリセット
python scripts/reset_test_db.py

# キャッシュのクリア
python scripts/clear_test_cache.py
```

## 6. トラブルシューティング

### 6.1 一般的な問題

1. テストの失敗
   - ログの確認
   - 環境変数の確認
   - テストデータの整合性確認

2. パフォーマンスの問題
   - リソース使用量の確認
   - キャッシュの状態確認
   - データベースの負荷確認

3. セキュリティの問題
   - 認証トークンの確認
   - アクセス権限の確認
   - ログの監査

### 6.2 エラーコード

| エラーコード | 説明 | 対処方法 |
|--------------|------|----------|
| TE-001 | テスト環境のセットアップ失敗 | 環境変数の確認 |
| TE-002 | テストデータの準備失敗 | データ生成スクリプトの確認 |
| TE-003 | データベース接続エラー | 接続設定の確認 |
| TE-004 | キャッシュ接続エラー | キャッシュサービスの確認 |
| TE-005 | テスト実行タイムアウト | タイムアウト設定の調整 |

## 7. メンテナンス

### 7.1 定期メンテナンス

1. テストケースの更新
   - 新機能のテストケース追加
   - 既存テストケースの見直し
   - テストデータの更新

2. テスト環境の更新
   - 依存パッケージの更新
   - テストデータベースの最適化
   - キャッシュのクリーンアップ

3. ドキュメントの更新
   - テスト仕様書の更新
   - トラブルシューティングガイドの更新
   - ベストプラクティスの更新

### 7.2 パフォーマンスモニタリング

1. メトリクスの収集
   - テスト実行時間
   - リソース使用量
   - エラー発生率

2. レポートの生成
   - 日次レポート
   - 週次レポート
   - 月次レポート

3. 改善アクション
   - パフォーマンスの最適化
   - テストケースの効率化
   - 環境の最適化 